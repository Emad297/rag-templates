# Summary of what we built
console.print("üéä Tutorial Complete! Here's what we accomplished:", style="green bold")
console.print("=" * 60, style="green")

accomplishments = [
    "‚úÖ Built a comprehensive GraphRAG system",
    "‚úÖ Combined vector embeddings with knowledge graphs", 
    "‚úÖ Created structured data models for medical symptoms",
    "‚úÖ Implemented SurrealDB integration for multi-model storage",
    "‚úÖ Developed graph traversal algorithms for enhanced retrieval",
    "‚úÖ Compared traditional RAG vs GraphRAG approaches",
    "‚úÖ Created a complete tutorial with working examples"
]

for item in accomplishments:
    console.print(f"  {item}")

console.print("\nüöÄ Next Steps and Extensions:", style="blue bold")
console.print("=" * 40, style="blue")

next_steps = [
    "üîß Connect to real SurrealDB and Ollama instances",
    "üìä Implement graph visualization with NetworkX or Plotly",
    "üß† Add more sophisticated embedding models (OpenAI, Cohere)",
    "üìà Implement graph algorithms (PageRank, community detection)",
    "üîç Add full-text search capabilities",
    "üåê Build a web interface with FastAPI or Streamlit",
    "üìö Expand to other domains (legal, financial, scientific)",
    "‚ö° Optimize performance with batch processing",
    "üîí Add security and user authentication",
    "üì± Create mobile or desktop applications"
]

for step in next_steps:
    console.print(f"  {step}")

console.print("\nüí° Key Benefits of GraphRAG:", style="magenta bold")
benefits = [
    "üéØ More accurate and contextual responses",
    "üîó Discovers hidden relationships in data", 
    "üìä Combines the best of vector search and graph databases",
    "üõ°Ô∏è Reduces hallucination through structured knowledge",
    "‚ö° Enables complex reasoning over interconnected data",
    "üé® Flexible for various domains and use cases"
]

for benefit in benefits:
    console.print(f"  {benefit}")

console.print("\nüìö Additional Resources:", style="yellow bold")
resources = [
    "üìñ SurrealDB Documentation: https://surrealdb.com/docs",
    "ü¶ú LangChain Documentation: https://docs.langchain.com",
    "ü§ñ Ollama Models: https://ollama.ai/library",
    "üìä Graph Algorithms: NetworkX, PyG, DGL",
    "üåê Web Frameworks: FastAPI, Streamlit, Gradio"
]

for resource in resources:
    console.print(f"  {resource}")

console.print("\n" + "=" * 60, style="green")
console.print("üôè Thank you for completing this GraphRAG tutorial!", style="green bold")
console.print("üöÄ Happy building with SurrealDB and LangChain!", style="blue bold")## üéä Conclusion and Next Steps

Congratulations! You've successfully built a GraphRAG system using SurrealDB and LangChain. Here's what we accomplished and what you can do next.class TraditionalRAG:
    """Traditional RAG implementation for comparison"""
    
    def __init__(self, embedding_manager: EmbeddingManager, vector_store: Dict[str, Any]):
        self.embedding_manager = embedding_manager
        self.vector_store = vector_store
    
    def query(self, user_query: str, k: int = 3) -> Dict[str, Any]:
        """Traditional RAG query using only vector similarity"""
        # Only vector search, no graph context
        vector_results = self.embedding_manager.similarity_search(user_query, self.vector_store, k)
        
        if not vector_results:
            response = \"I couldn't find any relevant information for your query.\"\n        else:\n            primary_symptom = vector_results[0]['metadata']['name']\n            treatments = vector_results[0]['metadata']['treatments']\n            response = f\"For '{user_query}', the most similar symptom is {primary_symptom}. Treatments: {', '.join(treatments)}.\"\n        \n        return {\n            \"query\": user_query,\n            \"response\": response,\n            \"vector_results\": vector_results\n        }\n\n# Comparison test\nif 'graphrag_engine' in locals() and 'vector_store' in locals():\n    traditional_rag = TraditionalRAG(embedding_manager, vector_store)\n    \n    comparison_query = \"What should I do for headache with nausea?\"\n    \n    console.print(\"‚öîÔ∏è Traditional RAG vs GraphRAG Comparison\", style=\"blue bold\")\n    console.print(\"=\" * 60, style=\"blue\")\n    console.print(f\"\\nQuery: '{comparison_query}'\", style=\"cyan bold\")\n    \n    # Traditional RAG response\n    console.print(\"\\nüîç Traditional RAG (Vector Search Only):\", style=\"yellow bold\")\n    traditional_result = traditional_rag.query(comparison_query)\n    console.print(traditional_result['response'], style=\"white\")\n    \n    if traditional_result['vector_results']:\n        console.print(\"\\nRetrieved symptoms:\")\n        for i, result in enumerate(traditional_result['vector_results'], 1):\n            console.print(f\"  {i}. {result['metadata']['name']} (Score: {result['score']})\")\n    \n    # GraphRAG response  \n    console.print(\"\\nüï∏Ô∏è GraphRAG (Vector + Graph Context):\", style=\"magenta bold\")\n    graphrag_result = graphrag_engine.query(comparison_query)\n    console.print(graphrag_result['response'], style=\"white\")\n    \n    # Show additional context from graph\n    graph_context = graphrag_result['context']['graph_context']\n    if graph_context:\n        console.print(\"\\nAdditional graph context:\")\n        for symptom, relations in graph_context.items():\n            if isinstance(relations, list) and relations:\n                console.print(f\"  {symptom}: connected to {len(relations)} entities\")\n                for rel in relations[:3]:  # Show first 3 relationships\n                    console.print(f\"    ‚Üí {rel['entity']} ({rel['type']})\")\n    \n    console.print(\"\\n\" + \"=\" * 60, style=\"blue\")\n    \n    # Summary of differences\n    console.print(\"\\nüìä Key Differences:\", style=\"green bold\")\n    differences = [\n        \"üîç Traditional RAG: Uses only vector similarity for retrieval\",\n        \"üï∏Ô∏è GraphRAG: Combines vector similarity + knowledge graph relationships\",\n        \"üìà GraphRAG provides richer context through entity relationships\",\n        \"üéØ GraphRAG can find connections that pure similarity might miss\",\n        \"üí° GraphRAG reduces hallucination by grounding in structured knowledge\"\n    ]\n    \n    for diff in differences:\n        console.print(f\"  {diff}\")\n        \nelse:\n    console.print(\"‚ö†Ô∏è Components not available for comparison\", style=\"yellow\")## üéØ Step 9: Comparison - Traditional RAG vs GraphRAG

Let's compare how traditional RAG (vector search only) performs versus our GraphRAG approach to highlight the benefits of graph relationships.# Test queries to demonstrate GraphRAG capabilities
test_queries = [
    "I have a headache and fever",
    "What helps with digestive issues?",
    "I'm experiencing respiratory problems",
    "My skin is itchy and red",
    "What treatments are available for neurological symptoms?"
]

# Run tests if GraphRAG engine is available
if 'graphrag_engine' in locals():
    console.print("üß™ Testing GraphRAG System", style="blue bold")
    console.print("=" * 50, style="blue")
    
    for i, query in enumerate(test_queries, 1):
        console.print(f"\nüìù Test {i}: {query}", style="cyan bold")
        console.print("-" * 40, style="cyan")
        
        try:
            # Get response from GraphRAG system
            result = graphrag_engine.query(query)
            
            # Display results
            console.print(f"\\nüí¨ Response:", style="green bold")
            console.print(result['response'], style="white")
            
            # Show retrieved context
            vector_results = result['context']['vector_results']\n            if vector_results:\n                console.print(f\"\\nüîç Retrieved {len(vector_results)} similar symptoms:\", style=\"yellow\")\n                for j, vr in enumerate(vector_results, 1):\n                    console.print(f\"  {j}. {vr['metadata']['name']} (Score: {vr['score']})\")\n            \n            # Show graph relationships\n            graph_context = result['context']['graph_context']\n            if graph_context:\n                console.print(f\"\\nüï∏Ô∏è Graph relationships:\", style=\"magenta\")\n                for symptom, relations in graph_context.items():\n                    if isinstance(relations, list) and relations:\n                        console.print(f\"  {symptom}: {len(relations)} connections\")\n            \n        except Exception as e:\n            console.print(f\"‚ùå Error processing query: {str(e)}\", style=\"red\")\n        \n        console.print(\"\\n\" + \"=\" * 50, style=\"blue\")\n        \nelse:\n    console.print(\"‚ö†Ô∏è GraphRAG engine not available for testing\", style=\"yellow\")\n    console.print(\"üí° Make sure all previous steps completed successfully\", style=\"blue\")## üß™ Step 8: Testing the GraphRAG System

Let's test our GraphRAG system with various queries to see how it combines vector search with graph knowledge!class GraphRAGEngine:
    """Main GraphRAG engine that combines vector search with graph traversal"""
    
    def __init__(self, embedding_manager: EmbeddingManager, kg_builder: KnowledgeGraphBuilder, vector_store: Dict[str, Any], config: GraphRAGConfig):
        self.embedding_manager = embedding_manager
        self.kg_builder = kg_builder
        self.vector_store = vector_store
        self.config = config
        
        # Initialize LLM (simulated for tutorial)
        try:
            self.llm = Ollama(
                base_url=config.OLLAMA_BASE_URL,
                model=config.OLLAMA_MODEL
            )
            console.print("‚úÖ LLM initialized successfully", style="green")
        except:
            console.print("‚ö†Ô∏è LLM not available, using simulated responses", style="yellow")
            self.llm = None
    
    def enhanced_retrieval(self, query: str, k_vector: int = 3, max_graph_depth: int = 2) -> Dict[str, Any]:
        """
        Enhanced retrieval combining vector search with graph traversal
        
        Args:
            query: User query
            k_vector: Number of similar documents to retrieve
            max_graph_depth: Maximum depth for graph traversal
            
        Returns:
            Dictionary containing retrieved context
        """
        # Step 1: Vector similarity search
        vector_results = self.embedding_manager.similarity_search(query, self.vector_store, k_vector)
        
        # Step 2: Graph traversal for additional context
        graph_context = {}
        for result in vector_results:
            symptom_name = result['metadata']['name']
            
            # Get related entities from graph
            related_entities = self.kg_builder.get_related_entities(symptom_name)
            graph_context[symptom_name] = related_entities
            
            # Find symptoms with common treatments
            for entity in related_entities:
                if entity['type'] == 'treatment':
                    connected_symptoms = self.kg_builder.find_connected_symptoms(entity['entity'])
                    if 'connected_symptoms' not in graph_context:
                        graph_context['connected_symptoms'] = set()
                    graph_context['connected_symptoms'].update(connected_symptoms)
        
        return {
            "vector_results": vector_results,
            "graph_context": graph_context,
            "query": query
        }
    
    def generate_response(self, retrieval_context: Dict[str, Any]) -> str:
        """
        Generate response based on retrieved context
        
        Args:
            retrieval_context: Context from enhanced retrieval
            
        Returns:
            Generated response string
        """
        query = retrieval_context["query"]
        vector_results = retrieval_context["vector_results"]
        graph_context = retrieval_context["graph_context"]
        
        # Build context string
        context_parts = []
        
        # Add vector search results
        context_parts.append("üîç SIMILAR SYMPTOMS:")
        for i, result in enumerate(vector_results, 1):
            context_parts.append(f"{i}. {result['metadata']['name']}: {result['metadata']['treatments']}")
        
        # Add graph context
        context_parts.append("\nüï∏Ô∏è RELATED INFORMATION:")
        for symptom, relations in graph_context.items():
            if isinstance(relations, list):
                context_parts.append(f"‚Ä¢ {symptom} is related to:")
                for rel in relations:
                    context_parts.append(f"  - {rel['entity']} ({rel['type']}) via {rel['relationship']}")
        
        context_string = "\n".join(context_parts)
        
        # Simulate LLM response if no actual LLM available
        if not self.llm:
            return self._simulate_response(query, vector_results, graph_context)
        
        # Create prompt for actual LLM
        prompt = f\"\"\"\nYou are a medical assistant. Based on the following context, provide a helpful response to the user's query.\n\nQuery: {query}\n\nContext:\n{context_string}\n\nResponse:\"\"\"\n        \n        try:\n            response = self.llm(prompt)\n            return response\n        except:\n            return self._simulate_response(query, vector_results, graph_context)\n    \n    def _simulate_response(self, query: str, vector_results: List[Dict], graph_context: Dict) -> str:\n        \"\"\"Simulate LLM response for tutorial purposes\"\"\"\n        if not vector_results:\n            return \"I couldn't find any relevant symptoms for your query. Please try rephrasing or provide more details.\"\n        \n        response_parts = []\n        response_parts.append(f\"Based on your query '{query}', here's what I found:\\n\")\n        \n        # Primary matches\n        primary_symptom = vector_results[0]['metadata']['name']\n        treatments = vector_results[0]['metadata']['treatments']\n        \n        response_parts.append(f\"The most relevant symptom appears to be **{primary_symptom}**.\")\n        response_parts.append(f\"Common treatments include: {', '.join(treatments)}.\\n\")\n        \n        # Related information from graph\n        if primary_symptom in graph_context:\n            related = graph_context[primary_symptom]\n            practices = [r['entity'] for r in related if r['type'] == 'practice']\n            if practices:\n                response_parts.append(f\"This is typically handled by: {', '.join(practices)}.\\n\")\n        \n        # Additional similar symptoms\n        if len(vector_results) > 1:\n            other_symptoms = [r['metadata']['name'] for r in vector_results[1:]]\n            response_parts.append(f\"You might also want to consider: {', '.join(other_symptoms)}.\")\n        \n        response_parts.append(\"\\n‚ö†Ô∏è This is for educational purposes only. Please consult a healthcare professional for medical advice.\")\n        \n        return \" \".join(response_parts)\n    \n    def query(self, user_query: str) -> Dict[str, Any]:\n        \"\"\"Main query interface for the GraphRAG system\"\"\"\n        console.print(f\"\\nü§î Processing query: '{user_query}'\", style=\"blue bold\")\n        \n        # Enhanced retrieval\n        retrieval_context = self.enhanced_retrieval(user_query)\n        \n        # Generate response\n        response = self.generate_response(retrieval_context)\n        \n        return {\n            \"query\": user_query,\n            \"response\": response,\n            \"context\": retrieval_context\n        }\n\n# Initialize GraphRAG engine\nif symptoms_data and 'vector_store' in locals() and 'kg_builder' in locals():\n    graphrag_engine = GraphRAGEngine(embedding_manager, kg_builder, vector_store, config)\n    console.print(\"‚úÖ GraphRAG engine initialized!\", style=\"green bold\")\nelse:\n    console.print(\"‚ö†Ô∏è Missing components for GraphRAG engine\", style=\"yellow\")## ü§ñ Step 7: GraphRAG Query Engine

Now comes the magic! Let's combine vector search with graph traversal to create our GraphRAG system.class KnowledgeGraphBuilder:
    """Builds and manages the knowledge graph for GraphRAG"""
    
    def __init__(self, symptoms: List[Symptom]):
        self.symptoms = symptoms
        self.graph = {
            "nodes": {"symptoms": {}, "treatments": {}, "practices": {}},
            "edges": {"treats": [], "practiced_by": []}
        }
        self._build_graph()
    
    def _build_graph(self):
        """Build the knowledge graph from symptoms data"""
        # Extract unique treatments and practices
        treatments = set()
        practices = set()
        
        for symptom in self.symptoms:
            # Add symptom node
            self.graph["nodes"]["symptoms"][symptom.name] = {
                "id": symptom.name,
                "description": symptom.description,
                "type": "symptom"
            }
            
            # Collect treatments and practices
            treatments.update(symptom.possible_treatments)
            practices.add(symptom.medical_practice)
            
            # Add treatment relationships
            for treatment in symptom.possible_treatments:
                self.graph["edges"]["treats"].append({
                    "from": symptom.name,
                    "to": treatment,
                    "type": "treats"
                })
            
            # Add practice relationship
            self.graph["edges"]["practiced_by"].append({
                "from": symptom.name,
                "to": symptom.medical_practice,
                "type": "practiced_by"
            })
        
        # Add treatment nodes
        for treatment in treatments:
            self.graph["nodes"]["treatments"][treatment] = {
                "id": treatment,
                "type": "treatment"
            }
        
        # Add practice nodes
        for practice in practices:
            self.graph["nodes"]["practices"][practice] = {
                "id": practice,
                "type": "practice"
            }
    
    def get_related_entities(self, entity_name: str, relationship_type: str = None) -> List[Dict]:
        """Get entities related to the given entity"""
        related = []
        
        for edge in self.graph["edges"]["treats"] + self.graph["edges"]["practiced_by"]:
            if edge["from"] == entity_name:
                if not relationship_type or edge["type"] == relationship_type:
                    # Find the target entity
                    for node_type, nodes in self.graph["nodes"].items():
                        if edge["to"] in nodes:
                            related.append({
                                "entity": edge["to"],
                                "type": node_type[:-1],  # Remove 's' from plural
                                "relationship": edge["type"]
                            })
        
        return related
    
    def find_connected_symptoms(self, treatment: str) -> List[str]:
        """Find symptoms connected to a specific treatment"""
        connected = []
        for edge in self.graph["edges"]["treats"]:
            if edge["to"] == treatment:
                connected.append(edge["from"])
        return connected
    
    def get_graph_summary(self) -> Dict[str, int]:
        """Get summary statistics of the knowledge graph"""
        return {
            "symptoms": len(self.graph["nodes"]["symptoms"]),
            "treatments": len(self.graph["nodes"]["treatments"]),
            "practices": len(self.graph["nodes"]["practices"]),
            "treatment_edges": len(self.graph["edges"]["treats"]),
            "practice_edges": len(self.graph["edges"]["practiced_by"])
        }

# Build the knowledge graph
if symptoms_data:
    kg_builder = KnowledgeGraphBuilder(symptoms_data)
    
    # Display graph summary
    summary = kg_builder.get_graph_summary()
    console.print("\nüï∏Ô∏è Knowledge Graph Summary:", style="blue bold")
    
    table = Table(title="Graph Statistics")
    table.add_column("Entity Type", style="cyan")
    table.add_column("Count", style="green")
    
    table.add_row("Symptoms", str(summary["symptoms"]))
    table.add_row("Treatments", str(summary["treatments"]))
    table.add_row("Medical Practices", str(summary["practices"]))
    table.add_row("Treatment Relationships", str(summary["treatment_edges"]))
    table.add_row("Practice Relationships", str(summary["practice_edges"]))
    
    console.print(table)
    
    # Example: Show relationships for a symptom
    test_symptom = symptoms_data[0].name
    related = kg_builder.get_related_entities(test_symptom)
    
    console.print(f"\nüîó Relationships for '{test_symptom}':", style="blue bold")
    for rel in related:
        console.print(f"  ‚Üí {rel['relationship']}: {rel['entity']} ({rel['type']})")
        
else:
    console.print("‚ö†Ô∏è No symptoms data available for graph building", style="yellow")## üï∏Ô∏è Step 6: Knowledge Graph Construction

This is where GraphRAG shines! Let's build a knowledge graph that captures relationships between symptoms, treatments, and medical practices.class EmbeddingManager:
    """Manages embeddings and vector storage operations"""
    
    def __init__(self, config: GraphRAGConfig):
        self.config = config
        try:
            # Initialize Ollama embeddings
            self.embeddings = OllamaEmbeddings(
                base_url=config.OLLAMA_BASE_URL,
                model=config.EMBEDDING_MODEL
            )
            console.print("‚úÖ Ollama embeddings initialized", style="green")
        except Exception as e:
            console.print(f"‚ö†Ô∏è  Ollama not available: {str(e)}", style="yellow")
            console.print("üí° Make sure Ollama is running with llama3.2 model", style="blue")
            self.embeddings = None
    
    def create_documents(self, symptoms: List[Symptom]) -> List[Document]:
        """Convert symptoms to LangChain documents for vector storage"""
        documents = []
        for symptom in symptoms:
            doc = symptom.to_document()
            documents.append(doc)
        
        console.print(f"üìÑ Created {len(documents)} documents for embedding", style="blue")
        return documents
    
    def simulate_embeddings(self, documents: List[Document]) -> Dict[str, Any]:
        """Simulate vector storage for tutorial purposes"""
        # Create a simple in-memory vector store simulation
        vector_store = {
            "documents": documents,
            "metadata": [doc.metadata for doc in documents],
            "content": [doc.page_content for doc in documents]
        }
        
        console.print(f"üóÑÔ∏è Simulated vector store with {len(documents)} documents", style="green")
        return vector_store
    
    def similarity_search(self, query: str, vector_store: Dict[str, Any], k: int = 3) -> List[Dict]:
        """Simulate similarity search for tutorial purposes"""
        # Simple keyword-based similarity for demonstration
        results = []
        query_lower = query.lower()
        
        for i, (doc, metadata, content) in enumerate(zip(
            vector_store["documents"], 
            vector_store["metadata"], 
            vector_store["content"]
        )):
            score = 0
            # Simple scoring based on keyword matches
            for word in query_lower.split():
                if word in content.lower():
                    score += 1
            
            if score > 0:
                results.append({
                    "document": doc,
                    "metadata": metadata,
                    "content": content,
                    "score": score
                })
        
        # Sort by score and return top k
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:k]

# Initialize embedding manager
embedding_manager = EmbeddingManager(config)

# Create documents from symptoms data
if symptoms_data:
    documents = embedding_manager.create_documents(symptoms_data)
    
    # Create vector store (simulated for tutorial)
    vector_store = embedding_manager.simulate_embeddings(documents)
    
    # Test similarity search
    test_query = "headache and fever"
    console.print(f"\nüîç Testing similarity search for: '{test_query}'", style="blue bold")
    
    search_results = embedding_manager.similarity_search(test_query, vector_store, k=3)
    
    for i, result in enumerate(search_results, 1):
        console.print(f"\n{i}. {result['metadata']['name']} (Score: {result['score']})")
        console.print(f"   Treatments: {', '.join(result['metadata']['treatments'])}")
else:
    console.print("‚ö†Ô∏è No symptoms data available for embedding", style="yellow")## üß† Step 5: Embeddings and Vector Store Setup

Now let's set up the embedding system and vector store for semantic similarity search. This is the first component of our GraphRAG system.class SurrealDBManager:
    """Manager class for SurrealDB operations"""
    
    def __init__(self, config: GraphRAGConfig):
        self.config = config
        self.db = None
        
    async def connect(self):
        """Connect to SurrealDB and set up namespace/database"""
        try:
            self.db = Surreal()
            await self.db.connect(self.config.SURREALDB_URL)
            await self.db.signin({
                "user": self.config.SURREALDB_USERNAME,
                "pass": self.config.SURREALDB_PASSWORD
            })
            await self.db.use(self.config.SURREALDB_NAMESPACE, self.config.SURREALDB_DATABASE)
            
            console.print("‚úÖ Connected to SurrealDB successfully", style="green")
            return True
            
        except Exception as e:
            console.print(f"‚ùå Failed to connect to SurrealDB: {str(e)}", style="red")
            console.print("üí° Make sure SurrealDB is running with: docker-compose up -d", style="yellow")
            return False
    
    async def setup_schema(self):
        """Set up database schema for graph nodes and relationships"""
        try:
            # Define schema for symptoms, treatments, and medical practices
            schema_queries = [
                # Symptom table
                "DEFINE TABLE symptom SCHEMAFULL;",
                "DEFINE FIELD name ON TABLE symptom TYPE string;",
                "DEFINE FIELD description ON TABLE symptom TYPE string;",
                "DEFINE FIELD medical_practice ON TABLE symptom TYPE string;",
                "DEFINE FIELD treatments ON TABLE symptom TYPE array;",
                "DEFINE FIELD embedding ON TABLE symptom TYPE array;",
                
                # Treatment table
                "DEFINE TABLE treatment SCHEMAFULL;",
                "DEFINE FIELD name ON TABLE treatment TYPE string;",
                "DEFINE FIELD description ON TABLE treatment TYPE string;",
                
                # Medical practice table  
                "DEFINE TABLE medical_practice SCHEMAFULL;",
                "DEFINE FIELD name ON TABLE medical_practice TYPE string;",
                "DEFINE FIELD description ON TABLE medical_practice TYPE string;",
                
                # Relationships
                "DEFINE TABLE treats SCHEMAFULL;",
                "DEFINE FIELD in ON TABLE treats TYPE record (symptom);",
                "DEFINE FIELD out ON TABLE treats TYPE record (treatment);",
                
                "DEFINE TABLE practiced_by SCHEMAFULL;",
                "DEFINE FIELD in ON TABLE practiced_by TYPE record (symptom);",
                "DEFINE FIELD out ON TABLE practiced_by TYPE record (medical_practice);",
            ]
            
            for query in schema_queries:
                await self.db.query(query)
            
            console.print("‚úÖ Database schema setup complete", style="green")
            return True
            
        except Exception as e:
            console.print(f"‚ùå Error setting up schema: {str(e)}", style="red")
            return False
    
    async def close(self):
        """Close database connection"""
        if self.db:
            await self.db.close()

# Initialize database manager
db_manager = SurrealDBManager(config)

# Connect to database (this will only work if SurrealDB is running)
console.print("üîó Attempting to connect to SurrealDB...", style="blue")
try:
    # Note: This will fail if SurrealDB is not running - that's okay for tutorial purposes
    import asyncio
    loop = asyncio.get_event_loop()
    if loop.is_running():
        console.print("‚ÑπÔ∏è  Async loop already running - connection setup ready", style="yellow")
    else:
        # If no event loop, try to connect
        asyncio.run(db_manager.connect())
        asyncio.run(db_manager.setup_schema())
except Exception as e:
    console.print(f"‚ö†Ô∏è  SurrealDB not available: {str(e)}", style="yellow") 
    console.print("üí° Run 'docker-compose up -d' to start SurrealDB", style="blue")## üîó Step 4: Database Connection and Setup

Let's connect to SurrealDB and set up our database schema for both vector storage and graph relationships.def load_symptoms_data(file_path: str = "../data/symptoms.yaml") -> List[Symptom]:
    """
    Load and parse symptoms data from YAML file.
    
    Args:
        file_path: Path to the YAML file containing symptoms data
        
    Returns:
        List of Symptom objects
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = yaml.safe_load(file)
        
        symptoms = []
        for category in data:
            category_name = category['category']
            for symptom_data in category['symptoms']:
                symptom = Symptom(
                    name=symptom_data['name'],
                    description=symptom_data['description'],
                    medical_practice=symptom_data['medical_practice'],
                    possible_treatments=symptom_data['possible_treatments']
                )
                symptoms.append(symptom)
        
        console.print(f"‚úÖ Loaded {len(symptoms)} symptoms from {file_path}", style="green")
        return symptoms
        
    except Exception as e:
        console.print(f"‚ùå Error loading symptoms data: {str(e)}", style="red")
        return []

# Load the symptoms data
symptoms_data = load_symptoms_data()

# Display sample data
if symptoms_data:
    console.print("\nüìä Sample symptom data:", style="blue bold")
    for i, symptom in enumerate(symptoms_data[:3]):  # Show first 3
        console.print(f"\n{i+1}. {symptom.name}")
        console.print(f"   Description: {symptom.description}")
        console.print(f"   Practice: {symptom.medical_practice}")
        console.print(f"   Treatments: {', '.join(symptom.possible_treatments)}")## üóÑÔ∏è Step 3: Data Loading and Processing

Now let's load our symptom data and prepare it for the GraphRAG system. We'll parse the YAML file and create structured objects.# Data model classes for structured symptom data
@dataclass
class Symptom:
    name: str
    description: str
    medical_practice: str
    possible_treatments: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    def to_document(self) -> Document:
        """Convert symptom to LangChain document for vector storage"""
        content = f"Symptom: {self.name}\nDescription: {self.description}\nMedical Practice: {self.medical_practice}\nTreatments: {', '.join(self.possible_treatments)}"
        metadata = {
            "name": self.name,
            "medical_practice": self.medical_practice,
            "treatments": self.possible_treatments,
            "type": "symptom"
        }
        return Document(page_content=content, metadata=metadata)

@dataclass 
class GraphRAGConfig:
    """Configuration class for our GraphRAG system"""
    
    # Database configuration
    SURREALDB_URL: str = os.getenv("SURREALDB_URL", "ws://localhost:8000/rpc")
    SURREALDB_USERNAME: str = os.getenv("SURREALDB_USERNAME", "root")
    SURREALDB_PASSWORD: str = os.getenv("SURREALDB_PASSWORD", "root")
    SURREALDB_NAMESPACE: str = os.getenv("SURREALDB_NAMESPACE", "medical")
    SURREALDB_DATABASE: str = os.getenv("SURREALDB_DATABASE", "graphrag")
    
    # Ollama configuration
    OLLAMA_BASE_URL: str = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    OLLAMA_MODEL: str = os.getenv("OLLAMA_MODEL", "llama3.2")
    EMBEDDING_MODEL: str = os.getenv("EMBEDDING_MODEL", "llama3.2")
    
    # Collection names for our database
    VECTOR_COLLECTION: str = "symptom_vectors"
    GRAPH_NODES = {
        "symptom": "graph_Symptom",
        "treatment": "graph_Treatment", 
        "practice": "graph_Practice"
    }

config = GraphRAGConfig()

console.print("üìã Data models and configuration defined!", style="green bold")
console.print(f"üìç SurrealDB URL: {config.SURREALDB_URL}")
console.print(f"ü§ñ Ollama Model: {config.OLLAMA_MODEL}")def load_symptoms_data(file_path: str = "../data/symptoms.yaml") -> List[Symptom]:
    """
    Load and parse symptoms data from YAML file.
    
    Args:
        file_path: Path to the YAML file containing symptoms data
        
    Returns:
        List of Symptom objects
    """
    try:
        with open(file_path, "r") as f:
            data = yaml.safe_load(f)
        
        parsed_symptoms = []
        
        for category in data:
            console.print(f"üìÇ Processing category: {category['category']}")
            
            category_obj = Symptoms(
                category=category["category"], 
                symptoms=[]
            )
            
            for symptom_data in category["symptoms"]:
                symptom = Symptom(
                    name=symptom_data["name"],
                    description=symptom_data["description"],
                    medical_practice=symptom_data["medical_practice"],
                    possible_treatments=symptom_data["possible_treatments"]
                )
                
                category_obj.symptoms.append(symptom)
                parsed_symptoms.append(symptom)
        
        console.print(f"‚úÖ Loaded {len(parsed_symptoms)} symptoms from {len(data)} categories")
        return parsed_symptoms
        
    except FileNotFoundError:
        console.print(f"‚ùå File not found: {file_path}", style="red bold")
        console.print("üí° Make sure the symptoms.yaml file exists in the data/ directory", style="yellow")
        raise
    except Exception as e:
        console.print(f"‚ùå Error loading symptoms data: {e}", style="red bold")
        raise

def create_documents_from_symptoms(symptoms: List[Symptom]) -> List[Document]:
    """
    Convert Symptom objects to LangChain Document objects for vector storage.
    
    Each symptom becomes a document with:
    - page_content: The symptom description (what we'll search against)
    - metadata: All other symptom properties (name, treatments, etc.)
    
    Args:
        symptoms: List of Symptom objects
        
    Returns:
        List of LangChain Document objects
    """
    documents = []
    
    for symptom in symptoms:
        # Create document with description as main content
        doc = Document(
            page_content=symptom.description.strip(),
            metadata=asdict(symptom)  # Convert dataclass to dict for metadata
        )
        documents.append(doc)
    
    console.print(f"üìÑ Created {len(documents)} documents for vector storage")
    return documents

# Load and process the data
console.print("üîÑ Loading symptoms data...", style="blue bold")
symptoms_list = load_symptoms_data()

console.print("üîÑ Creating documents for vector storage...", style="blue bold")
symptom_documents = create_documents_from_symptoms(symptoms_list)

# Display sample data
console.print("\nüìã Sample Symptom Data:", style="bold")
table = Table(title="First 3 Symptoms")
table.add_column("Name", style="cyan")
table.add_column("Category", style="magenta") 
table.add_column("Description", style="white")
table.add_column("Treatments Count", style="green")

for i, symptom in enumerate(symptoms_list[:3]):
    # Find category by checking which category this symptom belongs to
    treatments_count = str(len(symptom.possible_treatments))
    table.add_row(
        symptom.name,
        "Medical",  # We could track category separately if needed
        symptom.description[:60] + "..." if len(symptom.description) > 60 else symptom.description,
        treatments_count
    )

console.print(table)## üìä Step 4: Data Loading and Preprocessing

Let's load our symptoms data and prepare it for both vector storage and graph construction. We'll parse the YAML file and create structured objects that can be used in both contexts.async def setup_database_connection():
    """
    Establishes connection to SurrealDB and returns the connection object.
    This function handles authentication and namespace/database selection.
    """
    try:
        # Create SurrealDB connection
        conn = Surreal(config.SURREALDB_URL)
        
        # Sign in with credentials
        await conn.signin({
            "user": config.SURREALDB_USER, 
            "pass": config.SURREALDB_PASSWORD
        })
        
        # Select namespace and database
        await conn.use(config.SURREALDB_NAMESPACE, config.SURREALDB_DATABASE)
        
        console.print("‚úÖ Successfully connected to SurrealDB!", style="green bold")
        return conn
        
    except Exception as e:
        console.print(f"‚ùå Failed to connect to SurrealDB: {e}", style="red bold")
        console.print("üí° Make sure SurrealDB is running: docker-compose up -d", style="yellow")
        raise

def initialize_langchain_components(conn):
    """
    Initialize LangChain components for our GraphRAG system.
    
    Returns:
        tuple: (embeddings, vector_store, graph_store, chat_model)
    """
    
    # Initialize embeddings model (for vector similarity search)
    embeddings = OllamaEmbeddings(model=config.EMBEDDING_MODEL)
    console.print(f"üî§ Initialized embeddings with model: {config.EMBEDDING_MODEL}")
    
    # Initialize vector store (for storing and searching document embeddings)
    vector_store = SurrealDBVectorStore(
        embeddings=embeddings,
        connection=conn,
        collection_name=config.VECTOR_COLLECTION
    )
    console.print(f"üì¶ Initialized vector store: {config.VECTOR_COLLECTION}")
    
    # Initialize graph store (for managing knowledge graph relationships)
    graph_store = SurrealDBGraph(conn)
    console.print("üï∏Ô∏è Initialized graph store")
    
    # Initialize chat model (for generating responses)
    chat_model = Ollama(model=config.OLLAMA_MODEL, temperature=0)
    console.print(f"üí¨ Initialized chat model: {config.OLLAMA_MODEL}")
    
    return embeddings, vector_store, graph_store, chat_model

# Execute the setup
console.print("üîÑ Setting up database connection...", style="blue bold")
conn = await setup_database_connection()

console.print("üîÑ Initializing LangChain components...", style="blue bold")
embeddings, vector_store, graph_store, chat_model = initialize_langchain_components(conn)

console.print("üéâ Setup complete! Ready to build our GraphRAG system.", style="green bold")## üîó Step 3: Database Connection and Setup

Now let's establish our connection to SurrealDB and initialize our LangChain components. SurrealDB's multi-model nature allows us to use both vector search and graph capabilities in a single database.@dataclass
class Symptom:
    """
    Represents a medical symptom with its properties and relationships.
    This structure matches our YAML data format and will be used to build our knowledge graph.
    """
    name: str
    description: str
    medical_practice: str
    possible_treatments: List[str]

@dataclass
class Symptoms:
    """
    Container for a category of symptoms.
    Helps organize symptoms by medical categories (e.g., Respiratory, Digestive, etc.)
    """
    category: str
    symptoms: List[Symptom]

# Configuration class for our GraphRAG system
class GraphRAGConfig:
    """
    Centralized configuration for our GraphRAG implementation.
    This makes it easy to modify settings without changing code throughout the notebook.
    """
    # SurrealDB settings
    SURREALDB_URL = os.getenv("SURREALDB_URL", "ws://localhost:8000/rpc")
    SURREALDB_USER = os.getenv("SURREALDB_USER", "root")
    SURREALDB_PASSWORD = os.getenv("SURREALDB_PASSWORD", "root")
    SURREALDB_NAMESPACE = os.getenv("SURREALDB_NAMESPACE", "test")
    SURREALDB_DATABASE = os.getenv("SURREALDB_DATABASE", "test")
    
    # LLM settings
    OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "llama3.2")
    
    # Collection names for our database
    VECTOR_COLLECTION = "symptom_vectors"
    GRAPH_NODES = {
        "symptom": "graph_Symptom",
        "treatment": "graph_Treatment", 
        "practice": "graph_Practice"
    }

config = GraphRAGConfig()

console.print("üìã Data models and configuration defined!", style="green bold")
console.print(f"üìç SurrealDB URL: {config.SURREALDB_URL}")
console.print(f"ü§ñ Ollama Model: {config.OLLAMA_MODEL}")## üèóÔ∏è Step 2: Data Models and Configuration

Let's define our data models and configuration. These classes will help us structure our symptom data and work with it programmatically.# Core libraries for data processing and async operations
import asyncio
import yaml
import json
import os
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
from pathlib import Path

# Environment and configuration
from dotenv import load_dotenv
load_dotenv()

# SurrealDB for our multi-model database
from surrealdb import Surreal

# LangChain components for GraphRAG
from langchain.schema import Document
from langchain.embeddings import OllamaEmbeddings
from langchain.llms import Ollama
from langchain.vectorstores import SurrealDBVectorStore
from langchain.graphs import SurrealDBGraph
from langchain.chains.graph_qa.surrealdb import SurrealDBGraphQAChain
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# For visualization and logging
import matplotlib.pyplot as plt
import pandas as pd
from rich.console import Console
from rich.table import Table
import warnings
warnings.filterwarnings('ignore')

# Initialize rich console for beautiful output
console = Console()

print("‚úÖ All imports successful! Let's build our GraphRAG system.")## üõ†Ô∏è Step 1: Environment Setup and Imports

First, let's import all the necessary libraries and set up our environment. Each import serves a specific purpose in our GraphRAG implementation.# GraphRAG with SurrealDB + LangChain Tutorial

Welcome to this comprehensive tutorial on building a **Graph Retrieval-Augmented Generation (GraphRAG)** chatbot using SurrealDB, LangChain, and Ollama!

## üéØ What We'll Build

In this tutorial, we'll create an intelligent medical symptom chatbot that combines:
- **Vector similarity search** for finding relevant symptoms
- **Knowledge graph traversal** for understanding relationships between symptoms, treatments, and medical practices
- **Large Language Models** for generating natural, contextual responses

## üß† Understanding GraphRAG vs Traditional RAG

### Traditional RAG
- Uses vector embeddings to find similar text chunks
- Limited to surface-level semantic similarity
- Can miss important relationships and context

### GraphRAG (What we're building)
- Combines vector search with graph relationships
- Understands connections between entities (symptoms ‚Üî treatments ‚Üî medical practices)
- Provides richer, more contextual responses
- Reduces hallucination by grounding responses in structured knowledge

## üìã Prerequisites

Before we start, make sure you have:
1. **Docker** installed and running
2. **SurrealDB** running (we'll set this up)
3. **Ollama** installed with llama3.2 model
4. **Python environment** with required packages

Let's begin! üöÄ